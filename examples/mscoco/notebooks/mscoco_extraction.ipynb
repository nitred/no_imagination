{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.display import Image as ImageIpy\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint, pformat\n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_project_directory(_1, _2, subset):\n",
    "    mscoco_dir = '/media/nitred/mydata/datasets/mscoco/2017'\n",
    "    return os.path.join(mscoco_dir, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(json_path):\n",
    "    \"\"\"Function to read json file.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_obj = json.loads(f.read())\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def get_ignore_ids(ignore_ids_path):\n",
    "    \"\"\".\"\"\"\n",
    "    print(\"Get Ignore Ids\", ignore_ids_path)\n",
    "    if os.path.isfile(ignore_ids_path):\n",
    "        # Read\n",
    "        with open(ignore_ids_path, 'rb') as f:\n",
    "            ignore_ids = pickle.load(f)\n",
    "            \n",
    "        # Corner case\n",
    "        if not isinstance(ignore_ids, list):\n",
    "            ignore_ids = []\n",
    "    else:\n",
    "        ignore_ids = []\n",
    "    \n",
    "    print(\"Ignore Ids: {}\".format(len(ignore_ids)))\n",
    "    return ignore_ids\n",
    "\n",
    "\n",
    "def update_ignore_ids(ignore_ids_path, ignore_ids):\n",
    "    \"\"\".\"\"\"\n",
    "    print(\"Updating Ignore Ids\", ignore_ids_path)\n",
    "    if os.path.isfile(ignore_ids_path):\n",
    "        # Read\n",
    "        with open(ignore_ids_path, 'rb') as f:\n",
    "            orig_ignore_ids = pickle.load(f)\n",
    "            print(\"Original Ignore Ids: {}\".format(len(orig_ignore_ids)))\n",
    "        \n",
    "        # Update\n",
    "        if isinstance(orig_ignore_ids, list):\n",
    "            new_ignore_ids = orig_ignore_ids + ignore_ids\n",
    "        else:\n",
    "            # Corner case\n",
    "            new_ignore_ids = ignore_ids\n",
    "    else:\n",
    "        # Update\n",
    "        new_ignore_ids = ignore_ids\n",
    "    \n",
    "    # Write\n",
    "    with open(ignore_ids_path, 'wb') as f:\n",
    "        pickle.dump(new_ignore_ids, f)\n",
    "        print(\"New Ignore Ids: {}\".format(len(new_ignore_ids)))\n",
    "\n",
    "\n",
    "def get_image_id_to_image_caption_category_dict_from_sub_dir(sub_dir):\n",
    "    \"\"\"Return dict object mapping image id to image details.\"\"\"\n",
    "    images_dir = os.path.join(sub_dir, 'images')\n",
    "    captions_json_path = os.path.join(sub_dir, 'captions.json')\n",
    "    stuff_json_path = os.path.join(sub_dir, 'stuff.json')\n",
    "    ignore_ids_path = os.path.join(sub_dir, 'ignore_ids.pkl')\n",
    "\n",
    "    captions_json = read_json_file(captions_json_path)\n",
    "    stuff_json = read_json_file(stuff_json_path)\n",
    "\n",
    "    # Get Image Dict from captions json\n",
    "    images_dict = {image['id']: image for image in captions_json['images']}\n",
    "\n",
    "    # Update Image Dict:\n",
    "    for key in images_dict.keys():\n",
    "        # Update with empty captions list\n",
    "        images_dict[key]['captions'] = []\n",
    "        # Update with empty category list\n",
    "        images_dict[key]['categories'] = []\n",
    "        # Full path to image\n",
    "        images_dict[key]['path'] = os.path.join(images_dir, images_dict[key]['file_name'])\n",
    "        images_dict[key]['path_128'] = os.path.join(images_dir, \"128_\" + images_dict[key]['file_name'])\n",
    "        images_dict[key]['path_224'] = os.path.join(images_dir, \"224_\" + images_dict[key]['file_name'])\n",
    "\n",
    "    # Update Image Dict:\n",
    "    for anno in captions_json['annotations']:\n",
    "        # Update the captions list from annotations\n",
    "        images_dict[anno['image_id']]['captions'].append(anno['caption'])\n",
    "\n",
    "    # Update Image Dict with categories\n",
    "    # images_dict['categories'] = stuff_json['categories']\n",
    "\n",
    "    # Update Image Dict:\n",
    "    for stuff_anno in stuff_json['annotations']:\n",
    "        # Update the categories list from stuff-annotations\n",
    "        images_dict[stuff_anno['image_id']]['categories'].append(stuff_anno['category_id'])\n",
    "\n",
    "    # Create Categories Dict:\n",
    "    categories_dict = {stuff_cat['id']: stuff_cat for stuff_cat in stuff_json['categories']}\n",
    "\n",
    "#     # Update Categories Dict:\n",
    "#     sorted_categories_ids = sorted(categories_dict.keys())\n",
    "#     sorted_categories_dict = {}\n",
    "#     for sorted_id, category_id in enumerate(sorted_categories_ids):\n",
    "#         sorted_categories_dict[sorted_id] = categories_dict[category_id]\n",
    "#         sorted_categories_dict[sorted_id]['sorted_id'] = sorted_id\n",
    "\n",
    "    # Remove ignore ids\n",
    "    ignore_ids = get_ignore_ids(ignore_ids_path)\n",
    "    for ignore_id in ignore_ids:\n",
    "        images_dict.pop(ignore_id, None)\n",
    "\n",
    "    return images_dict, categories_dict\n",
    "\n",
    "\n",
    "def generate_square_images(subset, images_dict, pixels):\n",
    "    \"\"\".\"\"\"\n",
    "    ignore_ids = np.empty(shape=[len(images_dict.keys())], dtype=int)\n",
    "    ignore_index = 0\n",
    "    for i, key in enumerate(images_dict.keys()):\n",
    "        image_dict = images_dict[key]\n",
    "        try:\n",
    "            pass\n",
    "            with open(image_dict['path'], 'r+b') as f:\n",
    "                with Image.open(f) as image:\n",
    "                    cover = resizeimage.resize_cover(image, [pixels, pixels, 3])\n",
    "                    # cover.save(image_dict['path_{}'.format(pixels)], image.format)\n",
    "        except resizeimage.ImageSizeError:\n",
    "            # print(\"{},\".format(image_dict['id']))\n",
    "            ignore_ids[ignore_index] = image_dict['id']\n",
    "            ignore_index += 1\n",
    "        except FileNotFoundError:\n",
    "            # print(\"{},\".format(image_dict['id']))\n",
    "            ignore_ids[ignore_index] = image_dict['id']\n",
    "            ignore_index += 1\n",
    "                \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Iter: {}, Ignored: {}\".format(i, ignore_index))\n",
    "    \n",
    "    ignore_ids = list(ignore_ids[:ignore_index])\n",
    "    \n",
    "    if ignore_ids:\n",
    "        subset_dir = get_project_directory('mscoco', 'dataset', subset)\n",
    "        ignore_ids_path = os.path.join(subset_dir, 'ignore_ids.pkl')\n",
    "        update_ignore_ids(ignore_ids_path, ignore_ids)\n",
    "            \n",
    "\n",
    "def get_images_and_categories_dict(subset):\n",
    "    \"\"\".\n",
    "\n",
    "    Args:\n",
    "        subset (str): 'train' or 'test' or 'val'.\n",
    "    \"\"\"\n",
    "    mscoco_sub_dir = get_project_directory('mscoco', 'dataset', subset)\n",
    "    images_dict, categories_dict = get_image_id_to_image_caption_category_dict_from_sub_dir(mscoco_sub_dir)\n",
    "\n",
    "    return images_dict, categories_dict\n",
    "\n",
    "\n",
    "def get_n_random_categories(categories_dict, n_categories):\n",
    "    \"\"\"Return random .\"\"\"\n",
    "    np.random.seed(seed=11111)\n",
    "    random_slice = list(np.random.permutation(len(categories_dict.keys()))[:n_categories])\n",
    "    random_n_categories = list(np.array(sorted(categories_dict.keys()))[random_slice])\n",
    "    return random_n_categories\n",
    "\n",
    "\n",
    "def get_filtered_image_dict_from_categories(images_dict, categories):\n",
    "    \"\"\".\"\"\"\n",
    "    filtered_images_dict = {}\n",
    "\n",
    "    for key in images_dict.keys():\n",
    "        image_dict = images_dict[key]\n",
    "        # Get one intersection\n",
    "        intersection_category = list(set(categories).intersection(set(image_dict['categories'])))[:1]\n",
    "        if intersection_category:\n",
    "            intersection_category = intersection_category[0]\n",
    "            filtered_images_dict[key] = image_dict\n",
    "            filtered_images_dict[key]['chosen_category_id'] = intersection_category\n",
    "            # Label is the index of the category in the list of categories\n",
    "            chosen_category_label = categories.index(intersection_category)\n",
    "            filtered_images_dict[key]['chosen_category_label'] = chosen_category_label\n",
    "\n",
    "    return filtered_images_dict\n",
    "\n",
    "\n",
    "def get_filtered_mage_dict_for_subset_for_n_categories(subset, n_categories=10):\n",
    "    \"\"\".\"\"\"\n",
    "    images_dict, categories_dict = get_images_and_categories_dict(subset)\n",
    "    random_n_categories = get_n_random_categories(categories_dict, n_categories)\n",
    "    filtered_images_dict = get_filtered_image_dict_from_categories(images_dict, random_n_categories)\n",
    "    return filtered_images_dict, categories_dict\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\".\"\"\"\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    # short_edge = min(img.shape[:2])\n",
    "    # yy = int((img.shape[0] - short_edge) / 2)\n",
    "    # xx = int((img.shape[1] - short_edge) / 2)\n",
    "    # crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # # resize to 224, 224\n",
    "    # resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    return img\n",
    "\n",
    "\n",
    "def add_faulty_images_to_ignore(subset):\n",
    "    \"\"\".\"\"\"\n",
    "    images_dict, categories_dict = get_images_and_categories_dict(subset)\n",
    "    subset_dir = get_project_directory('mscoco', 'dataset', subset)\n",
    "    ignore_ids_path = os.path.join(subset_dir, \"ignore_ids.pkl\")\n",
    "    ignore_ids_ndim = []\n",
    "    ignore_ids_exception = []\n",
    "    for key in images_dict.keys():\n",
    "        image_dict = images_dict[key]\n",
    "        try:\n",
    "            img = load_image(image_dict['path_224'])\n",
    "            if not img.ndim == 3:\n",
    "                ignore_ids_ndim.append(image_dict['id'])\n",
    "        except Exception as ex:\n",
    "            ignore_ids_exception.append(image_dict['id'])\n",
    "    \n",
    "    ignore_ids = ignore_ids_ndim + ignore_ids_exception\n",
    "    if ignore_ids:\n",
    "        update_ignore_ids(ignore_ids_path, ignore_ids)\n",
    "        \n",
    "            \n",
    "def one_hot_encoding(arr, n_categories):\n",
    "    \"\"\".\"\"\"\n",
    "    n_rows = len(arr)\n",
    "    one_hot = np.zeros(shape=[n_rows, n_categories], dtype=int)\n",
    "    # Magic.\n",
    "    one_hot[np.arange(n_rows), arr.astype(int)] = 1\n",
    "    return one_hot\n",
    "    \n",
    "\n",
    "\n",
    "class mscoco_generator(object):\n",
    "    \"\"\".\"\"\"\n",
    "\n",
    "    def __init__(self, subset='val', n_categories=10, batch_size=32):\n",
    "        \"\"\".\"\"\"\n",
    "        self.subset = subset\n",
    "        self.n_categories = n_categories\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.images_dict, self.categories_dict = get_filtered_mage_dict_for_subset_for_n_categories(\n",
    "            self.subset, self.n_categories)\n",
    "\n",
    "        self.batch_generator = self.__generate_batches()\n",
    "\n",
    "    def __generate_batches(self):\n",
    "        \"\"\".\"\"\"\n",
    "        start_index = 0\n",
    "        images_keys = np.array(sorted(self.images_dict.keys()))\n",
    "\n",
    "        # shuffle deterministically\n",
    "        np.random.seed(seed=11111)\n",
    "        np.random.shuffle(images_keys)\n",
    "\n",
    "        while True:\n",
    "            batch_indices = range(start_index, start_index + self.batch_size, 1)\n",
    "            batch_keys = images_keys.take(batch_indices, mode='wrap')\n",
    "            start_index += self.batch_size\n",
    "\n",
    "            batch_x = np.empty([self.batch_size, 224, 224, 3])\n",
    "            batch_y = np.empty([self.batch_size, 1])\n",
    "\n",
    "            # Load batch\n",
    "            for i, image_key in enumerate(batch_keys):\n",
    "                batch_x[i] = load_image(self.images_dict[image_key]['path_224'])\n",
    "                batch_y[i] = float(self.images_dict[image_key]['chosen_category_label'])\n",
    "\n",
    "            batch_y_one_hot = one_hot_encoding(batch_y.ravel(), self.n_categories)\n",
    "            \n",
    "            # Yield batch\n",
    "            yield batch_x, batch_y_one_hot\n",
    "\n",
    "    def next_batch(self):\n",
    "        \"\"\".\"\"\"\n",
    "        return next(self.batch_generator)\n",
    "\n",
    "    def reset_generator(self):\n",
    "        \"\"\".\"\"\"\n",
    "        self.batch_generator = self.__generate_batches()\n",
    "\n",
    "    def get_category_mapping(self):\n",
    "        \"\"\".\"\"\"\n",
    "        category_labels = list(range(self.n_categories))\n",
    "        category_names = []\n",
    "        for category_label in category_labels:\n",
    "            for key in self.images_dict.keys():\n",
    "                if category_label == self.images_dict[key]['chosen_category_label']:\n",
    "                    category_id = self.images_dict[key]['chosen_category_id']\n",
    "                    category_name = self.categories_dict[category_id]['name']\n",
    "                    super_category_name = self.categories_dict[category_id]['supercategory']\n",
    "                    category_names.append([category_label, category_id, category_name, super_category_name])\n",
    "                    break\n",
    "        return category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Ignore Ids /media/nitred/mydata/datasets/mscoco/2017/val/ignore_ids.pkl\n",
      "Ignore Ids: 2\n"
     ]
    }
   ],
   "source": [
    "images_dict, categories_dict = get_images_and_categories_dict('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Ignore Ids /media/nitred/mydata/datasets/mscoco/2017/val/ignore_ids.pkl\n",
      "Ignore Ids: 12\n",
      "Get Ignore Ids /media/nitred/mydata/datasets/mscoco/2017/val/ignore_ids.pkl\n",
      "Ignore Ids: 12\n"
     ]
    }
   ],
   "source": [
    "images_dict, categories_dict = get_images_and_categories_dict('val')\n",
    "# generate_square_images('val', images_dict, pixels=224)\n",
    "add_faulty_images_to_ignore('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Manual Manipulation\n",
    "```\n",
    "Manually Created the following to 224x224\n",
    "\n",
    "/media/nitred/mydata/datasets/mscoco/2017/val/images/000000456394.jpg\n",
    "/media/nitred/mydata/datasets/mscoco/2017/val/images/000000149770.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Ignored: 0\n",
      "Iter: 1000, Ignored: 100\n",
      "Iter: 2000, Ignored: 195\n",
      "Iter: 3000, Ignored: 301\n",
      "Iter: 4000, Ignored: 404\n",
      "Iter: 5000, Ignored: 502\n",
      "Iter: 6000, Ignored: 608\n",
      "Iter: 7000, Ignored: 707\n",
      "Iter: 8000, Ignored: 791\n",
      "Iter: 9000, Ignored: 901\n",
      "Iter: 10000, Ignored: 1008\n",
      "Iter: 11000, Ignored: 1102\n",
      "Iter: 12000, Ignored: 1200\n",
      "Iter: 13000, Ignored: 1308\n",
      "Iter: 14000, Ignored: 1401\n",
      "Iter: 15000, Ignored: 1489\n",
      "Iter: 16000, Ignored: 1582\n",
      "Iter: 17000, Ignored: 1690\n",
      "Iter: 18000, Ignored: 1783\n",
      "Iter: 19000, Ignored: 1889\n",
      "Iter: 20000, Ignored: 1991\n",
      "Iter: 21000, Ignored: 2095\n",
      "Iter: 22000, Ignored: 2193\n",
      "Iter: 23000, Ignored: 2291\n",
      "Iter: 24000, Ignored: 2394\n",
      "Iter: 25000, Ignored: 2502\n",
      "Iter: 26000, Ignored: 2599\n",
      "Iter: 27000, Ignored: 2688\n",
      "Iter: 28000, Ignored: 2781\n",
      "Iter: 29000, Ignored: 2872\n",
      "Iter: 30000, Ignored: 2967\n",
      "Iter: 31000, Ignored: 3064\n",
      "Iter: 32000, Ignored: 3162\n",
      "Iter: 33000, Ignored: 3258\n",
      "Iter: 34000, Ignored: 3361\n",
      "Iter: 35000, Ignored: 3454\n",
      "Iter: 36000, Ignored: 3555\n",
      "Iter: 37000, Ignored: 3652\n",
      "Iter: 38000, Ignored: 3741\n",
      "Iter: 39000, Ignored: 3824\n",
      "Iter: 40000, Ignored: 3926\n",
      "Iter: 41000, Ignored: 4017\n",
      "Iter: 42000, Ignored: 4128\n",
      "Iter: 43000, Ignored: 4198\n",
      "Iter: 44000, Ignored: 4295\n",
      "Iter: 45000, Ignored: 4390\n",
      "Iter: 46000, Ignored: 4484\n",
      "Iter: 47000, Ignored: 4580\n",
      "Iter: 48000, Ignored: 4669\n",
      "Iter: 49000, Ignored: 4765\n",
      "Iter: 50000, Ignored: 4858\n",
      "Iter: 51000, Ignored: 4954\n",
      "Iter: 52000, Ignored: 5057\n",
      "Iter: 53000, Ignored: 5143\n",
      "Iter: 54000, Ignored: 5242\n",
      "Iter: 55000, Ignored: 5342\n",
      "Iter: 56000, Ignored: 5437\n",
      "Iter: 57000, Ignored: 5551\n",
      "Iter: 58000, Ignored: 5650\n",
      "Iter: 59000, Ignored: 5742\n",
      "Iter: 60000, Ignored: 5843\n",
      "Iter: 61000, Ignored: 5942\n",
      "Iter: 62000, Ignored: 6039\n",
      "Iter: 63000, Ignored: 6132\n",
      "Iter: 64000, Ignored: 6247\n",
      "Iter: 65000, Ignored: 6354\n",
      "Iter: 66000, Ignored: 6448\n",
      "Iter: 67000, Ignored: 6548\n",
      "Iter: 68000, Ignored: 6638\n",
      "Iter: 69000, Ignored: 6738\n",
      "Iter: 70000, Ignored: 6841\n",
      "Iter: 71000, Ignored: 6948\n",
      "Iter: 72000, Ignored: 7044\n",
      "Iter: 73000, Ignored: 7155\n",
      "Iter: 74000, Ignored: 7255\n",
      "Iter: 75000, Ignored: 7358\n",
      "Iter: 76000, Ignored: 7436\n",
      "Iter: 77000, Ignored: 7523\n",
      "Iter: 78000, Ignored: 7620\n",
      "Iter: 79000, Ignored: 7698\n",
      "Iter: 80000, Ignored: 7794\n",
      "Iter: 81000, Ignored: 7903\n",
      "Iter: 82000, Ignored: 8005\n",
      "Iter: 83000, Ignored: 8103\n",
      "Iter: 84000, Ignored: 8198\n",
      "Iter: 85000, Ignored: 8318\n",
      "Iter: 86000, Ignored: 8411\n",
      "Iter: 87000, Ignored: 8518\n",
      "Iter: 88000, Ignored: 8613\n",
      "Iter: 89000, Ignored: 8717\n",
      "Iter: 90000, Ignored: 8815\n",
      "Iter: 91000, Ignored: 8916\n",
      "Iter: 92000, Ignored: 9006\n",
      "Iter: 93000, Ignored: 9102\n",
      "Iter: 94000, Ignored: 9188\n",
      "Iter: 95000, Ignored: 9275\n",
      "Iter: 96000, Ignored: 9362\n",
      "Iter: 97000, Ignored: 9469\n",
      "Iter: 98000, Ignored: 9572\n",
      "Iter: 99000, Ignored: 9679\n",
      "Iter: 100000, Ignored: 9772\n",
      "Iter: 101000, Ignored: 9865\n",
      "Iter: 102000, Ignored: 9980\n",
      "Iter: 103000, Ignored: 10085\n",
      "Iter: 104000, Ignored: 10183\n",
      "Iter: 105000, Ignored: 10277\n",
      "Iter: 106000, Ignored: 10373\n",
      "Iter: 107000, Ignored: 10468\n",
      "Iter: 108000, Ignored: 10557\n",
      "Iter: 109000, Ignored: 10661\n",
      "Iter: 110000, Ignored: 10749\n",
      "Iter: 111000, Ignored: 10854\n",
      "Iter: 112000, Ignored: 10949\n",
      "Iter: 113000, Ignored: 11036\n",
      "Iter: 114000, Ignored: 11132\n",
      "Iter: 115000, Ignored: 11232\n",
      "Iter: 116000, Ignored: 11315\n",
      "Iter: 117000, Ignored: 11398\n",
      "Iter: 118000, Ignored: 11499\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db35e0c6659d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimages_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_and_categories_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_square_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5ac2b47c34af>\u001b[0m in \u001b[0;36mgenerate_square_images\u001b[0;34m(subset, images_dict, pixels)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0msubset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_project_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mscoco'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mignore_ids_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore_ids.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_ids_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "# images_dict, categories_dict = get_images_and_categories_dict('train')\n",
    "# generate_square_images('train', images_dict, pixels=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iter: 0, Ignored: 0\n",
    "Iter: 1000, Ignored: 100\n",
    "Iter: 2000, Ignored: 195\n",
    "Iter: 3000, Ignored: 301\n",
    "Iter: 4000, Ignored: 404\n",
    "Iter: 5000, Ignored: 502\n",
    "Iter: 6000, Ignored: 608\n",
    "Iter: 7000, Ignored: 707\n",
    "Iter: 8000, Ignored: 791\n",
    "Iter: 9000, Ignored: 901\n",
    "Iter: 10000, Ignored: 1008\n",
    "Iter: 11000, Ignored: 1102\n",
    "Iter: 12000, Ignored: 1200\n",
    "Iter: 13000, Ignored: 1308\n",
    "Iter: 14000, Ignored: 1401\n",
    "Iter: 15000, Ignored: 1489\n",
    "Iter: 16000, Ignored: 1582\n",
    "Iter: 17000, Ignored: 1690\n",
    "Iter: 18000, Ignored: 1783\n",
    "Iter: 19000, Ignored: 1889\n",
    "Iter: 20000, Ignored: 1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(images_dict.keys())\n",
    "images_dict[222564]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_dict, categories_dict = get_images_and_categories_dict('test')\n",
    "# generate_square_images(images_dict, pixels=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored ids: 2\n",
      "ERROR: 353180\n",
      "ERROR: 61418\n",
      "ERROR: 209222\n",
      "ERROR: 353180\n",
      "ERROR: 61418\n",
      "ERROR: 209222\n",
      "ERROR: 353180\n",
      "ERROR: 61418\n",
      "ERROR: 209222\n",
      "ERROR: 353180\n",
      "ERROR: 61418\n"
     ]
    }
   ],
   "source": [
    "mscoco = mscoco_generator(subset='val', n_categories=10, batch_size=32)\n",
    "for i in range(200):\n",
    "    bx, by = mscoco.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, by = mscoco.next_batch()\n",
    "by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image in bx:\n",
    "    plt.figure()\n",
    "    skimage.io.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mscoco.category_labels_to_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i, c = get_images_and_categories_dict('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
